# 콘서트 예약 시스템 부하 테스트 계획서

---

## 핵심 요약
본 시스템은 **티켓팅 서비스 특성상 특정 시간대(예약 오픈 시점)에 수만 건의 동시 트래픽이 집중**되는 환경에서 운영된다는 것을 가정합니다. <br>
현재 Redis 기반 대기열(Semaphore + Sorted Set)과 SSE를 활용한 실시간 순번 알림 구조를 적용하고 있으나, **실 트래픽 환경에서의 성능 검증이 이루어지지 않은 상태**입니다.

### 부하 테스트가 필요한 근거
1. **비즈니스 리스크**: 예약 오픈 시점 장애 발생 시 고객 불만 및 매출 손실 직결
2. **기술적 불확실성**: Redis Semaphore(100 permits), SSE 장시간 연결(10분), Pub/Sub 브로드캐스트 성능 미검증
3. **SLA 정의 필요**: 목표 동시 접속자 수, 응답시간, 처리량에 대한 정량적 기준 부재
4. **인프라 증설 기준 부재**: 현재 리소스로 감당 가능한 한계치 파악 불가

### 요청 사항
- **부하 테스트 환경 구성 기간**: 2주 (환경 구축 1주 + 테스트 수행 및 분석 1주)
- **필요 인프라**: 프로덕션 유사 환경 (Application Server 3대, MySQL 1대, Redis 1대, 부하 발생기 1대)
- **예상 산출물**: 성능 테스트 보고서, SLA/SLO 권고안, 인프라 증설 시뮬레이션 결과

---

## 1. 시스템 컨텍스트

### 1.1 서비스 유형

**Spring Boot 3.4.1 기반 콘서트 예약 REST API**
- **서비스 도메인**: 티켓팅/예약 플랫폼
- **핵심 비즈니스**: 콘서트 예약, 대기열 관리, 좌석 선점, 결제 처리
- **사용자 행동 패턴**: 예약 오픈 시점 집중 트래픽 (Burst Traffic)

### 1.2 아키텍처
- **설계 패턴**: Hexagonal Architecture (Ports & Adapters) + DDD
- **모듈 구성**: 8개 Bounded Context (concerts, reservations, waiting, payments, points, users, venues, shared)
- **배포 환경**: Docker 컨테이너 (추후 Kubernetes 전환 고려)

### 1.3 기술 스택
| 계층 | 기술 |
|-----|-----|
| Runtime | Java 17 |
| Framework | Spring Boot 3.4.1 |
| Database | MySQL 8.0 (HikariCP, max pool size: 3) |
| Cache/Queue | Redis (Redisson) |
| Message Broker | Kafka (예약 완료 이벤트 발행) |
| Concurrency Control | ShedLock (JDBC), Redisson 분산락, AOP 기반 락 |

### 1.4 핵심 플로우
```
[사용자]
  → 대기열 진입 (Semaphore 100개 제한)
  → SSE 연결 (실시간 순번 알림, 10분 유지)
  → 입장 허가 (3초 주기 스케줄러)
  → 좌석 홀딩 (Redis, 5분 TTL, 분산락)
  → 결제 (포인트 차감, 멱등성 보장)
  → 예약 확정 (MySQL 저장, Kafka 이벤트 발행)
```

---

## 2. 부하 테스트 대상 선정
### 2.1 테스트 우선순위 매트릭스
| 기능 | 비즈니스 임팩트 | 기술 복잡도 | 동시성 수준 | 우선순위 |
|-----|--------------|-----------|----------|---------|
| 대기열 진입 및 SSE 연결 | **높음** (매출 직결) | **높음** (Redis + SSE + Pub/Sub) | **매우 높음** (수만 건 동시) | **P0** |
| 좌석 홀딩 | **높음** (중복 예약 방지) | **높음** (분산락 + 멱등성) | **높음** (수천 건 동시) | **P0** |
| 결제 처리 | **높음** (금전 관련) | **중간** (RDB 멱등성) | **중간** (홀딩 이후 분산) | **P1** |
| 예약 확정 | 중간 (결제 후 자동 처리) | 낮음 (단순 INSERT) | 낮음 (결제 후속) | P2 |
| 콘서트 조회 | 낮음 (정보성) | 낮음 (ReadOnly) | 높음 (캐싱 가능) | P2 |

### 2.2 P0 대상 상세 분석
1. 대기열 시스템 (Waiting Queue)
    - **선정 근거**:
      - 예약 오픈 시점 **첫 1분간 수만 명이 동시 진입**하는 특성
      - **SSE 장시간 연결**(10분)로 인한 메모리 및 네트워크 대역폭 소모
      - Redis Semaphore **100 permits 제한**이 실제 처리량에 미치는 영향 미검증
      - **Redis Pub/Sub 브로드캐스트** 성능 (다중 인스턴스 환경)
      - **ShedLock 기반 스케줄러** 동시성 제어 검증 필요

    - **예상 트래픽 패턴**:
      - 오픈 1분 이내: 20,000 동시 접속 시도
      - SSE 연결 유지: 평균 5분 (최대 10분)
      - 스케줄러 처리 주기: 3초(입장), 5초(순번 알림)

    - **비즈니스 임팩트**:
      - 대기열 장애 = 전체 예약 플로우 중단
      - 고객 불만 → 브랜드 신뢰도 하락
      - 경쟁사 대비 서비스 품질 저하


2. 좌석 홀딩 (Seat Hold)
    - **선정 근거**:
      - **AOP 기반 분산락**(@DistributedLock) 경합 성능 검증 필요
      - **Redis 멱등성 키** 처리 (동일 요청 중복 방지)
      - **데드락 방지 로직**(sorted lock) 실효성 확인
      - 5분 TTL 만료 시 **자동 해제 처리량** 검증

   - **예상 트래픽 패턴**:
      - 입장 허가 직후 1분간: 5,000 TPS
      - 동일 좌석 대상 경합: 최대 100건 동시 요청

   - **비즈니스 임팩트**:
      - 중복 예약 발생 시 법적 리스크
      - 락 타임아웃 과다 발생 시 고객 이탈

---

## 3. 부하 테스트 목적
### 3.1 정량적 목표
본 테스트는 단순 TPS 측정을 넘어 **운영 가능 여부 판단 기준**을 도출합니다.

| 지표 | 목표값 | 측정 방법 |
|-----|-------|---------|
| **SLA (Service Level Agreement)** | 99.5% 가용성 | 1시간 테스트 중 장애 시간 < 3분 |
| **SLO (Service Level Objective)** | 대기열 진입 응답시간 P95 < 1초 | JMeter Aggregate Report |
| **대기열 입장 처리량** | 100명/3초 (2,000명/분) | Redis Semaphore 처리량 모니터링 |
| **SSE 연결 안정성** | 10,000 동시 연결 유지 | Emitter Map 메모리 사용량, GC 빈도 |
| **좌석 홀딩 동시성** | 5,000 TPS (락 대기시간 < 500ms) | Redisson Lock Metrics |
| **결제 멱등성 보장** | 중복 결제 0건 | 동일 멱등성 키 100건 동시 요청 시 1건만 처리 |

### 3.2 정성적 목표
#### (1) 병목 지점 식별
- **Application Layer**: 스케줄러 처리 지연, SSE 브로드캐스트 병목
- **Infrastructure Layer**: Redis Semaphore 처리량, MySQL Connection Pool 고갈
- **Network Layer**: SSE 장시간 연결로 인한 대역폭 포화

#### (2) 리소스 증설 기준 도출
- **현재 구성**(App 3대, MySQL 1대, Redis 1대)으로 감당 가능한 **한계 동시 접속자 수**
- 목표 트래픽(예: 5만 동시 접속) 달성을 위한 **인프라 증설 시뮬레이션**
  - App Server Scale-out: 3대 → 10대
  - Redis Cluster 전환 필요 여부
  - MySQL Read Replica 필요 여부

#### (3) 장애 발생 시 임계점 파악
- **Redis Semaphore 고갈**: 100 permits 모두 사용 시 대기열 길이 증가 속도
- **SSE 연결 한계**: 단일 인스턴스당 최대 연결 수 (메모리/파일 디스크립터 한계)
- **MySQL Connection Pool 고갈**: HikariCP max pool size 3 → 증설 필요 시점
- **Kafka Lag 발생**: 예약 완료 이벤트 발행 지연 시점

---

## 4. 부하 테스트 시나리오
### 4.1 시나리오 설계 철학
실제 사용자 행동을 모방하되, **최악의 상황(Worst Case)**을 시뮬레이션합니다.

### 4.2 Phase 1: Baseline (정상 트래픽)
**목적**: 정상 운영 환경에서의 베이스라인 성능 측정

| 항목 | 값 |
|-----|---|
| 동시 사용자(VU) | 500명 |
| 지속 시간 | 10분 |
| TPS | ~100 |
| 시나리오 비율 | 대기열 진입 70%, 좌석 홀딩 20%, 결제 10% |

**기대 결과**:
- 모든 요청 성공률 > 99%
- P95 응답시간 < 500ms
- CPU 사용률 < 50%
- 메모리 사용률 < 60%

**실패 기준**:
- 에러율 > 1%
- P95 응답시간 > 1초
- MySQL Connection Pool 대기 발생

### 4.3 Phase 2: Peak Traffic (예약 오픈 시뮬레이션)

**목적**: 예약 오픈 시점 1분간 트래픽 집중 상황 재현

```
Ramp-up: 0 → 10,000 VU (30초)
Peak: 10,000 VU 유지 (1분)
Ramp-down: 10,000 → 2,000 VU (1분)
Steady: 2,000 VU 유지 (5분)
```

**세부 시나리오**:
1. **10,000명 동시 대기열 진입**
   - `POST /api/v1/waiting/reservation/enter`
   - Semaphore 획득 실패 → Sorted Set 추가

2. **SSE 연결 수립**
   - `GET /api/v1/waiting/reservation/subscribe`
   - 10분간 연결 유지 (Heartbeat 포함)

3. **스케줄러 처리 모니터링**
   - 3초마다 100명씩 입장 허가 (Semaphore release)
   - 5초마다 전체 대기자에게 순번 알림 (Pub/Sub)

**기대 결과**:
- 대기열 진입 성공률 100%
- SSE 연결 성공률 > 95%
- 입장 허가 지연 < 10초 (이론값: 3초 주기)
- Redis Pub/Sub 메시지 손실 0건

**실패 기준**:
- SSE 연결 실패율 > 5%
- 입장 허가 지연 > 30초
- Redis Semaphore Dead Lock 발생
- Application Server OOM (Out of Memory)

### 4.4 Phase 3: Stress Test (한계 테스트)
**목적**: 시스템 한계점 파악 및 Graceful Degradation 검증
```
Ramp-up: 0 → 30,000 VU (2분)
Peak: 30,000 VU 유지 (5분)
```

**장애 유발 시나리오**:
1. **Redis 지연 시뮬레이션**
   - Redis에 인위적 지연(100ms) 주입 → Semaphore 처리량 저하

2. **MySQL Connection Pool 고갈**
   - 장시간 쿼리 실행 → HikariCP 대기 큐 증가

3. **GC Pressure**
   - SSE Emitter Map 메모리 누적 → Full GC 빈도 증가

**기대 결과**:
- **Circuit Breaker 동작**: Redis 장애 시 대기열 대신 즉시 실패 응답
- **Rate Limiting**: 과도한 요청 시 429 응답
- **Graceful Shutdown**: Pod 재시작 시 SSE 연결 정상 종료

**실패 기준**:
- Application Server Crash
- Silent Failure (에러 로그 없이 요청 무응답)
- 데이터 정합성 깨짐 (중복 예약, 포인트 이중 차감)

### 4.5 Phase 4: Soak Test (장시간 안정성)
**목적**: 장시간 운영 시 메모리 누수, 리소스 고갈 검증
```
Steady: 2,000 VU 유지 (2시간)
```

**모니터링 지표**:
- Heap Memory 증가 추이 (메모리 누수 감지)
- Redis 메모리 사용량 (TTL 만료 처리 검증)
- MySQL Connection 누수 여부
- Kafka Consumer Lag 누적 여부

**기대 결과**:
- 메모리 사용량 안정적 유지 (증가 추세 없음)
- GC 빈도 일정 유지
- 모든 요청 응답시간 일정 유지

**실패 기준**:
- Heap Memory 지속 증가 (누수 의심)
- GC 빈도 증가 또는 Full GC 시간 > 1초
- 응답시간 점진적 증가 (리소스 고갈)

---

## 5. 테스트 방식 및 도구 선정
### 5.1 부하 발생 도구: Apache JMeter
**선정 이유**:
- **성숙한 생태계**: 20년 이상 검증된 오픈소스 부하 테스트 도구
- **GUI 기반 시나리오 작성**: 복잡한 사용자 플로우를 Test Plan으로 시각화
- **다양한 프로토콜 지원**: HTTP/HTTPS, WebSocket, JDBC, JMS, SMTP 등
- **풍부한 플러그인**: Plugins Manager를 통한 확장 가능 (SSE, Kafka, Redis)
- **대규모 부하 생성**: Distributed Testing으로 여러 머신에서 동시 부하 생성
- **실시간 모니터링**: Backend Listener를 통한 Grafana/InfluxDB 연동

**k6/Locust 대비 장점**:
- 기업 표준으로 널리 채택 (국내 대기업 대부분 사용)
- 비개발자도 사용 가능한 GUI 인터페이스
- 상세한 리포트 생성 (HTML, CSV, XML)
- 플러그인 생태계 (JMeter Plugins: PerfMon, Ultimate Thread Group 등)

### 5.2 시나리오 구성

#### (1) 단일 API 테스트

**목적**: 각 API 단독 성능 측정 (다른 요소 배제)

**JMeter Test Plan 구성**:
```
Thread Group (500 users, 10분)
  └─ HTTP Request Sampler: 대기열 진입 API
      - Method: POST
      - URL: http://localhost:8080/api/v1/waiting/reservation/enter
      - Body: { "userId": ${__threadNum}, "scheduleId": 1 }
      - Headers: Content-Type=application/json
  └─ Response Assertion
      - Response Code: 200
      - Response Time: < 1000ms
  └─ Aggregate Report (Listener)
      - 평균/P95/P99 응답시간
      - TPS, 에러율
```

#### (2) End-to-End 시나리오

**목적**: 실제 사용자 행동 모방 (전체 플로우)

**JMeter Test Plan 구성**:
```
Thread Group (10,000 users, Ramp-up 30초)
  ├─ HTTP Request: 대기열 진입
  │   └─ JSON Extractor: userKey, admittedToken 추출
  │
  ├─ If Controller (admitted == false)
  │   └─ WebSocket Sampler: SSE 구독 (10분 대기)
  │       └─ While Controller: 입장 허가 메시지 대기
  │
  ├─ HTTP Request: 좌석 홀딩
  │   └─ JSON Extractor: seatIds 추출
  │
  ├─ HTTP Request: 결제 처리
  │   └─ JSON Extractor: paymentId 추출
  │
  └─ HTTP Request: 예약 조회
      └─ Response Assertion: status == CONFIRMED
```

**필수 JMeter 플러그인**:
- `WebSocket Samplers by Peter Doornbosch` (SSE 테스트)
- `JSON Extractor` (응답 파싱)
- `Ultimate Thread Group` (복잡한 Ramp-up/down 패턴)

### 5.3 테스트 단계 (Test Phases)

모든 시나리오는 다음 단계를 거칩니다:

```
1. Warm-up (2분): 0 → 100 VU
   - Application JIT 컴파일 완료
   - Connection Pool 초기화
   - Redis 캐시 워밍

2. Ramp-up (가변): 100 VU → Target VU
   - 시나리오별 증가 속도 다름
   - Peak: 30초, Stress: 2분

3. Peak (가변): Target VU 유지
   - Baseline: 10분
   - Peak: 1분
   - Stress: 5분

4. Cool-down (1분): Target VU → 0
   - 진행 중 트랜잭션 완료 대기
```

### 5.4 모니터링 스택

| 계층 | 도구 | 수집 메트릭 |
|-----|-----|----------|
| Application | Micrometer + Prometheus | JVM (Heap, GC), HTTP (Latency, TPS), Custom (Semaphore 사용량) |
| Infrastructure | Node Exporter | CPU, Memory, Network I/O, Disk I/O |
| Database | MySQL Exporter | Connection Pool, Query Duration, Slow Query |
| Cache | Redis Exporter | Keyspace, Memory, Command Stats |
| Load Test | JMeter Backend Listener (InfluxDB) | Thread Count, Response Time, Error Rate |
| Visualization | Grafana | 실시간 대시보드 (전체 메트릭 통합) |

---

## 6. 인프라/시간 요청 근거

### 6.1 로컬/단순 테스트의 한계

**로컬 환경(단일 인스턴스)으로는 검증 불가능한 요소**:

1. **다중 인스턴스 동작**
   - ShedLock 분산 스케줄러 동시성 제어
   - Redis Pub/Sub 브로드캐스트 (여러 인스턴스로 메시지 전파)
   - SSE Emitter Map 분산 저장 (각 인스턴스 로컬)

2. **네트워크 병목**
   - Load Balancer 레이어에서의 Connection 처리
   - SSE 장시간 연결로 인한 대역폭 소모

3. **실제 부하 규모**
   - 로컬 PC에서 10,000 VU 생성 불가 (메모리/CPU 한계)
   - 프로덕션 수준 데이터 볼륨 (MySQL 수백만 건 레코드)

4. **장애 복구 시나리오**
   - Pod 재시작 시 SSE 재연결
   - Redis failover 시 Semaphore 복구

### 6.2 필요 인프라 상세

#### 6.2.1 테스트 환경 (프로덕션 유사)

| 리소스 | 스펙 | 수량 | 용도 |
|-------|-----|-----|-----|
| Application Server | 4 vCPU, 8GB RAM | 3대 | Spring Boot 인스턴스 |
| MySQL | 4 vCPU, 16GB RAM, SSD 100GB | 1대 | 메인 DB |
| Redis | 2 vCPU, 8GB RAM | 1대 | 대기열, 캐시 |
| Load Balancer | - | 1대 | Nginx/HAProxy |
| Load Generator | 8 vCPU, 16GB RAM | 1대 | JMeter 실행 (30,000 Thread 생성) |

**예상 클라우드 비용** (AWS 기준, 2주):
- EC2 t3.xlarge (App 3대): $0.166/h * 24h * 14d * 3 = $168
- RDS db.t3.large: $0.145/h * 24h * 14d = $49
- ElastiCache t3.medium: $0.068/h * 24h * 14d = $23
- **총합: 약 $250 (환율 1,300원 기준 32만원)**

#### 6.2.2 필요 기간

| 작업 | 기간 | 담당 |
|-----|-----|-----|
| 테스트 환경 구성 (IaC) | 2일 | DevOps |
| JMeter 테스트 계획 작성 | 2일 | Backend |
| 모니터링 대시보드 구성 | 1일 | SRE |
| Baseline/Peak 테스트 수행 | 2일 | Backend/SRE |
| Stress/Soak 테스트 수행 | 2일 | Backend/SRE |
| 데이터 분석 및 보고서 작성 | 3일 | All |
| **총 소요 기간** | **12일 (2주)** | - |

### 6.3 테스트 미수행 시 리스크

#### 6.3.1 비즈니스 리스크

| 리스크 | 발생 확률 | 영향도 | 예상 손실 |
|-------|---------|-------|---------|
| 예약 오픈 시점 전체 장애 | **높음** | **치명적** | 매출 손실 + 브랜드 이미지 타격 |
| 중복 예약 발생 (동시성 버그) | 중간 | 높음 | 법적 분쟁, 고객 보상 |
| 대기열 무한 대기 (입장 미처리) | 높음 | 높음 | 고객 이탈, CS 비용 증가 |
| SSE 연결 끊김 (메모리 부족) | 중간 | 중간 | 고객 불편, 재접속 부하 증가 |

**실제 사례**:
- A사 티켓팅 서비스: 예약 오픈 5분 만에 서버 다운 → 긴급 공지 및 재오픈 (SNS 비난 여론)
- B사 커머스: 타임세일 시 결제 지연 30분 → 고객 이탈률 40% 증가

#### 6.3.2 기술 부채

- **긴급 패치 비용**: 장애 발생 후 야간/주말 긴급 대응 (인건비 3배)
- **신뢰도 하락**: "우리 시스템 트래픽 감당 못함" 인식 고착화
- **엔지니어 사기 저하**: 준비 없이 운영 투입 → 잦은 장애 대응 번아웃

---

## 7. 예상 산출물

### 7.1 성능 테스트 보고서

**포함 내용**:
1. Executive Summary (경영진용 1페이지 요약)
2. 테스트 환경 및 시나리오 상세
3. 측정 결과 (그래프, 표)
   - TPS/Latency 추이
   - 에러율
   - 리소스 사용률 (CPU/Memory/Network)
4. 병목 지점 분석
   - Application: 스케줄러 지연, SSE 브로드캐스트
   - Database: Connection Pool 대기, Slow Query
   - Cache: Redis Semaphore 경합
5. 개선 권고안
   - 코드 레벨 최적화 (예: Semaphore 100 → 200 증설)
   - 인프라 증설 시뮬레이션

### 7.2 SLA/SLO 권고안

**SLA (고객 약속)**:
- 예약 오픈 시간 ±5분 내 99.5% 가용성 보장
- 대기열 순번 알림 지연 < 10초

**SLO (내부 목표)**:
- 대기열 진입 API P95 응답시간 < 1초
- 좌석 홀딩 API P99 응답시간 < 3초
- SSE 연결 성공률 > 95%

### 7.3 인프라 증설 시뮬레이션

**현재 구성으로 감당 가능한 한계**:
- 동시 접속자: 약 5,000명 (추정)
- SSE 동시 연결: 약 3,000개/인스턴스 (총 9,000개)

**목표 트래픽(5만 동시 접속) 달성 방안**:
1. Application Server Scale-out: 3대 → 15대
2. Redis Cluster 전환 (Sharding)
3. MySQL Read Replica 3대 추가
4. 예상 추가 비용: 월 $2,000 (약 260만원)

### 7.4 CI/CD 통합 스크립트

**자동화된 성능 테스트**:
- PR 머지 시 자동 부하 테스트 실행 (Baseline 시나리오)
- 성능 저하 10% 이상 시 알림
- JMeter 테스트 계획 템플릿 제공

---

## 8. 결론

본 시스템은 **티켓팅 특성상 예측 불가능한 피크 트래픽**에 노출되어 있으며, 현재 구성으로는 **실 트래픽 수용 가능 여부를 판단할 근거가 없습니다**.

부하 테스트를 통해:
1. **정량적 SLA/SLO 수립** → 고객 약속 가능
2. **병목 지점 사전 파악** → 장애 예방
3. **인프라 증설 계획 수립** → 예산 확보 근거

**2주간 부하 테스트 환경 구성 및 수행을 통해 시스템 안정성을 검증**하고, **프로덕션 배포 전 리스크를 최소화**할 수 있습니다.

---

## A. 참고 자료
### A.1 관련 파일 위치
- 대기열 서비스: `waiting/application/service/ReservationWaitingService.java:44`
- 좌석 홀딩: `reservations/application/service/HoldSeatService.java:52`
- 결제 처리: `payments/application/service/PayReservationService.java:59`
- 스케줄러: `waiting/infra/adapter/in/scheduler/ReservationWaitingScheduler.java:23`

### A.2 핵심 설정값
- Redis Semaphore: 100 permits (scheduleId당)
- SSE Timeout: 10분 (600,000ms)
- 좌석 홀드 TTL: 5분
- MySQL Connection Pool: HikariCP max 3
- 스케줄러 주기: 입장 3초, 순번 알림 5초
